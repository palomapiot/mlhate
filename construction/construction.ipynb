{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Create MetaHateES"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4bd66091a443c11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "my_datasets = [\n",
    "    (1, 'DETESTS 2024'), \n",
    "    (2, 'EXIST 2O21 & 2023'),\n",
    "    (3, 'HaSCoSVa'),\n",
    "    (4, 'HaterNet'),\n",
    "    (5, 'NewsCom-TOX'),\n",
    "    (6, 'OffendES'),\n",
    "    (7, 'SemEval 2019 Hateval'),\n",
    "    (8, 'Spanish MisoCorpus 2020'),\n",
    "    (9, 'HateFootball'),   \n",
    "    (10, 'MeTwo'),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c20691b73fb9fd5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. DETESTS\n",
    "# Two text genres: comments on news articles (detests) and posts on Twitter reacting to hoaxes (stereohoax) about the integration of immigrants\n",
    "# Uses part of the data from NewsCom-TOX\n",
    "# Convert data to format: text, label (0-1), source (twitter or news), dataset (detests2024), content_type (stereotype), variation (europe)\n",
    "df = pd.read_csv('data/detests2024.csv')\n",
    "df = df[['source', 'text', 'stereotype', 'implicit']]\n",
    "df = df.dropna()\n",
    "df.drop_duplicates(subset='text', keep=\"first\")\n",
    "df['source'].replace({'stereohoax': 'twitter', 'detests': 'news'}, inplace=True)\n",
    "df = df.rename(columns={'stereotype': 'label'})\n",
    "df['dataset'] = 'detests2024'\n",
    "df['content_type'] = 'sterotype'\n",
    "df['variation'] = 'europe'\n",
    "df = df[['label', 'text', 'source', 'variation', 'dataset', 'content_type']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "decbd866191fe893"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# 2. EXIST 2023\n",
    "# Convert data to format: text, label (0-1), source (twitter), dataset (exist2023), content_type (sexism), variation (europe)\n",
    "df_train = pd.read_csv('data/exist2023.tsv', sep='\\t')\n",
    "df_dev = pd.read_csv('data/exist2023_dev.tsv', sep='\\t')\n",
    "df = pd.concat([df_train, df_dev])\n",
    "df = df[df['lang'] == 'es']\n",
    "df = df[['tweet', 'labels_task1', 'labels_task2']]\n",
    "df = df.dropna()\n",
    "df = df.rename(columns={'tweet': 'text'})\n",
    "df.drop_duplicates(subset='text', keep=\"first\")\n",
    "\n",
    "def calculate_label(row):\n",
    "    majority_task1_yes = row[\"labels_task1\"].count(\"YES\") >= len(row[\"labels_task1\"]) / 2\n",
    "    majority_task2 = sum(label in [\"JUDGEMENTAL\", \"DIRECT\"] for label in row[\"labels_task2\"]) >= len(row[\"labels_task2\"]) / 2\n",
    "    return 1 if majority_task1_yes and majority_task2 else 0\n",
    "df[\"label\"] = df.apply(calculate_label, axis=1)\n",
    "df['source'] = 'twitter'\n",
    "df['dataset'] = 'exist2023'\n",
    "df['content_type'] = 'sexism'\n",
    "df['variation'] = 'europe'\n",
    "df = df[['label', 'text', 'source', 'variation', 'dataset', 'content_type']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T09:09:00.156729Z",
     "start_time": "2024-11-15T09:09:00.089870Z"
    }
   },
   "id": "7e033a3c9bf5b0b5"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# 2. EXIST 2021\n",
    "# Convert data to format: text, label (0-1), source (twitter, gab), dataset (exist2021), content_type (sexism), variation (europe)\n",
    "df_train = pd.read_csv('data/exist2021_train.tsv', sep='\\t')\n",
    "df_test = pd.read_csv('data/exist2021_test.tsv', sep='\\t')\n",
    "df = pd.concat([df_train, df_test])\n",
    "df = df[df['language'] == 'es']\n",
    "df = df[['text', 'source', 'task1']]\n",
    "df = df.dropna()\n",
    "df = df.rename(columns={'task1': 'label'})\n",
    "df.drop_duplicates(subset='text', keep=\"first\")\n",
    "df['dataset'] = 'exist2021'\n",
    "df['content_type'] = 'sexism'\n",
    "df['variation'] = 'europe'\n",
    "df = df[['label', 'text', 'source', 'variation', 'dataset', 'content_type']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T09:17:41.829576Z",
     "start_time": "2024-11-15T09:17:41.684310Z"
    }
   },
   "id": "1099360e97258926"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 3. HaSCoSVa\n",
    "# Convert data to format: text, label (0-1), source (twitter), dataset (hascosva), content_type (hate_speech)\n",
    "df = pd.read_csv('data/hascosva.tsv', sep='\\t')\n",
    "df = df.dropna()\n",
    "df.drop_duplicates(subset='text', keep=\"first\")\n",
    "df['dataset'] = 'hascosva'\n",
    "df['source'] = 'twitter'\n",
    "df['content_type'] = 'hate_speech'\n",
    "df = df[['label', 'text', 'source', 'variation', 'dataset', 'content_type']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-10T13:30:06.097933Z",
     "start_time": "2025-02-10T13:30:06.038605Z"
    }
   },
   "id": "229a1085a4d3a64c"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# 4. HaterNet\n",
    "# Convert data to format: text, label (0-1), source (twitter), dataset (haternet), content_type (hate_speech)\n",
    "df = pd.read_csv('data/haternet.tsv', sep='\\t')\n",
    "df = df.dropna()\n",
    "df.drop_duplicates(subset='text', keep=\"first\")\n",
    "df['dataset'] = 'haternet'\n",
    "df['source'] = 'twitter'\n",
    "df['content_type'] = 'hate_speech'\n",
    "df['variation'] = 'europe'\n",
    "df = df[['label', 'text', 'source', 'variation', 'dataset', 'content_type']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-08T17:07:32.854631Z",
     "start_time": "2024-11-08T17:07:32.770098Z"
    }
   },
   "id": "79277add0caa360e"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 5. NewsCom-TOX\n",
    "# Convert data to format: text, label (0-1), source (twitter), dataset (newscom-tox), content_type (toxicity)\n",
    "df_train = pd.read_csv('data/newscom-tox_train.csv', sep=',')\n",
    "df_test = pd.read_csv('data/newscom-tox_test.csv', sep=',')\n",
    "df = pd.concat([df_train, df_test])\n",
    "df = df[['comment', 'toxicity']]\n",
    "df = df.dropna()\n",
    "df = df.rename(columns={'comment': 'text'})\n",
    "df.drop_duplicates(subset='text', keep=\"first\")\n",
    "df = df.rename(columns={'toxicity': 'label'})\n",
    "df['dataset'] = 'newscom-tox'\n",
    "df['source'] = 'news'\n",
    "df['content_type'] = 'toxicity'\n",
    "df['variation'] = 'europe'\n",
    "df = df[['label', 'text', 'source', 'variation', 'dataset', 'content_type']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-10T14:50:28.761156Z",
     "start_time": "2025-02-10T14:50:28.647711Z"
    }
   },
   "id": "7142475074031a99"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 6. OffendES\n",
    "# Convert data to format: text, label (0-1), source (twitter), dataset (offendes), content_type (offensive)\n",
    "df_dev = pd.read_csv('data/offendes_dev.tsv', sep='\\t')\n",
    "df_test = pd.read_csv('data/offendes_test.tsv', sep='\\t')\n",
    "df_train = pd.read_csv('data/offendes_train.tsv', sep='\\t')\n",
    "df = pd.concat([df_dev, df_test, df_train])\n",
    "df = df.dropna()\n",
    "df.drop_duplicates(subset='comment', keep=\"first\")\n",
    "df['label'].replace({'NO': 0, 'NOE': 0, 'OFG': 1, 'OFP': 1 }, inplace=True)\n",
    "df = df.rename(columns={'comment': 'text'})\n",
    "df['dataset'] = 'offendes'\n",
    "df['source'] = df['media']\n",
    "df['content_type'] = 'offensive'\n",
    "df['variation'] = 'europe'\n",
    "df = df[['label', 'text', 'source', 'variation', 'dataset', 'content_type']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcd6fb6a4898df2e"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# 7. SemEval 2019 HatEval\n",
    "# Convert data to format: text, label (0-1), source (twitter), dataset (hateval), content_type (hate_speech)\n",
    "df_dev = pd.read_csv('data/hateval_dev.csv', sep=',')\n",
    "df_test = pd.read_csv('data/hateval_test.csv', sep=',')\n",
    "df_train = pd.read_csv('data/hateval_train.csv', sep=',')\n",
    "df = pd.concat([df_dev, df_test, df_train])\n",
    "df = df.dropna()\n",
    "df.drop_duplicates(subset='text', keep=\"first\")\n",
    "df = df.rename(columns={'HS': 'label'})\n",
    "df['dataset'] = 'hateval'\n",
    "df['source'] = 'twitter'\n",
    "df['content_type'] = 'hate_speech'\n",
    "df['variation'] = 'europe' # they use castilian spanish speaking annotators - the data is castilian spanish \n",
    "df = df[['label', 'text', 'source', 'variation', 'dataset', 'content_type']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-08T17:01:37.190052Z",
     "start_time": "2024-11-08T17:01:37.067532Z"
    }
   },
   "id": "712934d2e19a666b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 8. MisoCorpus\n",
    "# Convert data to format: text, label (0-1), source (twitter), dataset (misocorpus), content_type (hate_speech)\n",
    "df = pd.read_csv('data/misocorpus.csv', sep=',')\n",
    "df = df.dropna()\n",
    "df.drop_duplicates(subset='text', keep=\"first\")\n",
    "df['source'] = 'twitter'\n",
    "df['content_type'] = 'misogyny'\n",
    "df[\"variation\"] = df[\"post_author_country_location\"].apply(lambda x: \"europe\" if x == \"Spain\" else \"latam\")\n",
    "df = df.rename(columns={'labels': 'label'})\n",
    "df = df[['label', 'text', 'source', 'variation', 'dataset', 'content_type']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2d4f0407cbe3d17"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# 9. HateFootball\n",
    "df = pd.read_csv('data/hate-football.csv', sep=',')\n",
    "df = df.rename(columns={'tweet': 'text'})\n",
    "df[\"label\"] = df[\"label\"].apply(lambda x: 1 if \"racist\" in x or \"misogyny\" in x else 0)\n",
    "df['source'] = 'twitter'\n",
    "df['content_type'] = 'aggresive'\n",
    "df['variation'] = 'europe'\n",
    "df['dataset'] = 'hate-football'\n",
    "df = df[['label', 'text', 'source', 'variation', 'dataset', 'content_type']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-08T13:36:00.671358Z",
     "start_time": "2025-05-08T13:35:59.232868Z"
    }
   },
   "id": "fb1685ca93e6121d"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 10. MeTwo \n",
    "df = pd.read_csv('data/MeTwo.csv', sep=',')\n",
    "df[\"label\"] = df[\"categoria\"].apply(lambda x: 1 if x == \"SEXIST\" else 0)\n",
    "df['source'] = 'twitter'\n",
    "df['content_type'] = 'sexism'\n",
    "df['variation'] = 'europe' # expressions used to create the data are in castilian spanish\n",
    "df['dataset'] = 'metwo'\n",
    "df = df[['label', 'text', 'source', 'variation', 'dataset', 'content_type']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-11T08:16:14.706642Z",
     "start_time": "2025-02-11T08:16:14.664935Z"
    }
   },
   "id": "bdfe7968585d1955"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_names = [\n",
    "    'detests2024.tsv',\n",
    "    'exist2021.tsv',\n",
    "    'exist2023.tsv',\n",
    "    'hascosva.tsv',\n",
    "    'haternet.tsv',\n",
    "    'hateval.tsv',\n",
    "    'misocorpus.tsv',\n",
    "    'newscom-tox.tsv',\n",
    "    'offendes.tsv',\n",
    "    'hate-football.tsv',\n",
    "    'metwo.tsv',\n",
    "]\n",
    "\n",
    "full_df = pd.DataFrame()\n",
    "\n",
    "for name in dataset_names:\n",
    "    full_df = pd.concat([full_df, pd.read_csv(f'data/{name}', sep='\\t')])\n",
    "full_df.dropna(inplace=True)\n",
    "full_df.drop_duplicates(subset='text', keep=\"first\")\n",
    "full_df = full_df[full_df['variation'] == 'europe']\n",
    "full_df['label'] = full_df['label'].replace({'non-sexist': 0, 'sexist': 1})\n",
    "full_df['label'] = full_df['label'].replace({'0': 0, '1': 1})\n",
    "full_df['label'] = full_df['label'].replace({'0.0': 0, '1.0': 1})\n",
    "full_df['label'] = full_df['label'].astype(int)\n",
    "full_df.to_csv('data/MetaHateES.tsv', sep='\\t', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bf4769f1d671bcc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/MetaHateES.tsv', sep='\\t')\n",
    "\n",
    "summary = {}\n",
    "\n",
    "summary['Total samples'] = len(df)\n",
    "summary['Hate speech samples'] = f\"{(df['label'] == 1).sum()} ({(df['label'] == 1).mean():.2%})\"\n",
    "summary['Non-hate samples'] = f\"{(df['label'] == 0).sum()} ({(df['label'] == 0).mean():.2%})\"\n",
    "\n",
    "summary['Unique sources'] = df['source'].unique().tolist()\n",
    "summary['Unique datasets'] = df['dataset'].unique().tolist()\n",
    "dataset_count = df['dataset'].value_counts().head(15)\n",
    "summary['Count per dataset'] = dataset_count.to_dict()\n",
    "\n",
    "summary['Samples from Europe only'] = f\"{(df['variation'] == 'europe').sum()} ({(df['variation'] == 'only europe').mean():.2%})\"\n",
    "\n",
    "top_content = df['content_type'].value_counts().head(10)\n",
    "summary['Top 10 content types'] = top_content.to_dict()\n",
    "\n",
    "hate_by_content = df[df['content_type'].isin(top_content.index)]\n",
    "hate_pct_by_content = hate_by_content.groupby('content_type')['label'].mean().sort_values(ascending=False).apply(lambda x: f\"{x:.2%}\")\n",
    "summary['Hate by content type (top 10)'] = hate_pct_by_content.to_dict()\n",
    "\n",
    "hate_by_source = df.groupby('source')['label'].mean().sort_values(ascending=False).apply(lambda x: f\"{x:.2%}\")\n",
    "summary['Hate by source'] = hate_by_source.to_dict()\n",
    "\n",
    "hate_by_source_count = df[df['label'] == 1].groupby('source').size().sort_values(ascending=False)\n",
    "summary['Hate count by source'] = hate_by_source_count.to_dict()\n",
    "\n",
    "count_by_source = df.groupby('source').size().sort_values(ascending=False)\n",
    "summary['Count by source'] = count_by_source.to_dict()\n",
    "\n",
    "summary_df = pd.DataFrame.from_dict(summary, orient='index', columns=['Value'])\n",
    "\n",
    "summary_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4df1abfb06f6154"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[['content_type', 'source']].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac047b9cda862202"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
